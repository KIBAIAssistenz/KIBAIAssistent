{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "13645a6401094b8e9e43ee6439cebbb7",
    "deepnote_cell_type": "markdown"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "71dc5b3cd80f444c85229c5a5d134243",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "# BAI-Assistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8e372a10361b49d79135bb1ac2bc94e8",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "Grundidee: Hilft bei der Erstellung von Zusammenfassungen, welche auf Basis unseren Zusammenfassungen und Vorlesungsfolien die Antworten generiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "34e39c6b71ff43369582549ea792d7a4",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "#### Unsere Problemstellung\n",
    "Während der Prüfungsvorbereitung sind vor allem Erstsemester Studenten überfordert, wie man beim Lernen vorgehen kann. Daher haben wir es als Lücke vor allem im BAI-Studiengang erkannt.\n",
    "\n",
    "#### Use Cases: \n",
    "Ich möchte, dass mir der Lernassistent mir Fachbegriffe in ML und Einführung KI erklärt\n",
    "Ich möchte gut auf die Prüfungen durch den Lernassistenten vorbereitet werden\n",
    "-\tIch möchte Prüfungsfragen erhalten\n",
    "-\tIch möchte, dass es Merksätze gibt\n",
    "-\tIch möchte, dass die Erklärungen einfach sind\n",
    "-\tIch möchte Hilfe/Beratung erhalten, wie ich mein Cheat Sheet gemäss Stoffabgrenzung aufstellen kann\n",
    "Ich möchte schnelle und unlimitierte Antworten\n",
    "(Ich möchte Prüfungsfragen vom Chatbot erhalten, damit ich mich gut auf die Prüfung vorbereiten kann)\n",
    "\n",
    "##### Zielgruppe: \n",
    "BAI-Studenten im ersten Studienjahr, die Maschinelles Lernen und Einführung in die Künstliche Intelligenz belegen\n",
    "\n",
    "##### KPIs: \n",
    "•\tAntwortzeit < 5 Sekunden\n",
    "•\tPrüfungsnutzen > 70 % finden Quiz hilfreich\n",
    "•\tFachliche Korrektheit >85%\n",
    "\n",
    "Unsere Erwartungen: Fachbegriffe fragen, Unterschied zwischen Supervised und Unsupervised Learning, Was ist One Hot Encoding\n",
    "Inhalte für den KI-Assistenten: Folien Unterricht, Zusammenfassungen, Stoffabgrenzung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zusammenführung LLM und API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sende Test-Ping...\n",
      "Antworttyp: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Inhalt: pong\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Stelle sicher, dass dieser Key existiert ---\n",
    "assert \"GROQ_API_KEY_BAI\" in os.environ, \"GROQ_API_KEY fehlt in den Env Vars!\"\n",
    "\n",
    "# --- Initialisiere LLM explizit für OpenRouter ---\n",
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-oss-120b\",   \n",
    "    api_key=os.environ[\"GROQ_API_KEY_BAI\"],\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "print(\"Sende Test-Ping...\")\n",
    "try:\n",
    "    msg = llm.invoke(\"Sag exakt: pong\")\n",
    "    print(\"Antworttyp:\", type(msg))\n",
    "    # msg ist i.d.R. ein AIMessage – gib Inhalt sicher aus:\n",
    "    print(\"Inhalt:\", getattr(msg, \"content\", msg))\n",
    "except Exception as e:\n",
    "    print(\"FEHLER beim LLM-Aufruf:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "48703dda10da4a189aae9e8b27d1da51",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 1312,
    "execution_start": 1759758229079,
    "source_hash": "af9e9b5a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "#LLM_MODEL = \"openai/gpt-oss-20b:free\"\n",
    "LLM_MODEL = \"openai/gpt-oss-120b\"\n",
    "LLM_TEMPERATURE = 0.4\n",
    "BASE_URL = \"https://api.groq.com/openai/v1\"\n",
    "OPENROUTER_API_KEY = os.getenv(\"GROQ_API_KEY_BAI\")\n",
    "USER_PROMPT=\"Ich verstehe GenAI nicht, kannst du das mir einfach erklären?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "560a2f48c30445d0af462bee57df506a",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 2680,
    "execution_start": 1759758230441,
    "source_hash": "b9f7f98b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_MODEL,\n",
    "    temperature=LLM_TEMPERATURE,\n",
    "    base_url=BASE_URL,\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "print(type(llm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kurz sicherstellen, ob API Key funktioniert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pong\n",
      "False None\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(llm.invoke(\"Sag nur: pong\").content)\n",
    "except Exception as e:\n",
    "    print(repr(e))\n",
    "\n",
    "# Test 2: Env-Variablen sichtbar?\n",
    "import os\n",
    "print(\"OPENAI_API_KEY\" in os.environ, os.environ.get(\"OPENAI_BASE_URL\"))\n",
    "print(\"GROQ_API_KEY_BAI\" in os.environ)\n",
    "print(\"OPENROUTER_API_KEY\" in os.environ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatPrompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "a39ea2f0cef040f4bc860ac3c41a6a4d",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758233169,
    "source_hash": "90dbf177"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    " \n",
    "LERNASSISTENT_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        (\n",
    "            \"Sprache: Deutsch. Rolle: FHNW-BAI-Lernassistent; erkläre wie eine geduldige Lehrperson.\\n\"\n",
    "            \"Nutze AUSSCHLIESSLICH den bereitgestellten CONTEXT (Folien/Skripte).\\n\"\n",
    "            \"Wenn Informationen fehlen oder die Frage nicht im CONTEXT abgedeckt ist, antworte exakt:\\n\"\n",
    "            \"\\\"Dazu habe ich im bereitgestellten Material nichts.\\\" \\n\"\n",
    "            \"Schlage danach präzise nächste Schritte vor (z. B. welche Folie/Abschnitt hochzuladen wäre).\\n\"\n",
    "            \"Ziel: Studierende effizient auf Prüfungen vorbereiten.\\n\"\n",
    "            \"Stil: aktiv, konkret, ohne Floskeln, keine Gender-Sonderzeichen (nutze z. B. 'Lehrperson').\\n\"\n",
    "            \"Gib GENAU EINEN Lösungsvorschlag und EIN einfaches Beispiel.\\n\"\n",
    "            \"Halte dich an Terminologie aus dem CONTEXT. Keine externen Fakten, keine Spekulation.\\n\"\n",
    "            \"CONTEXT:\\n{context}\"\n",
    "        )\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        (\n",
    "            \"FRAGE: {question}\\n\"\n",
    "            \"Erstelle die Antwort in genau dieser Struktur:\\n\"\n",
    "            \"1) Kurzantwort (2–3 Sätze, prüfungsrelevant)\\n\"\n",
    "            \"2) Erklärung (max. 8 Sätze, schrittweise, mit Intuition)\\n\"\n",
    "            \"3) Beispiel (sehr einfach, kleine Zahlen/konkreter Mini-Fall)\\n\"\n",
    "            \"4) Typische Prüfungsfehler (Bullets)\\n\"\n",
    "            \"5) Verständnis-Check (1–2 Kontrollfragen)\\n\"\n",
    "            \"6) Quellen (Dokumenttitel + Seiten/Abschnitt aus CONTEXT)\"\n",
    "        )\n",
    "    ),\n",
    "])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "2f723a65eeb04432a1ba77dcfe049109",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 483,
    "execution_start": 1759758245649,
    "source_hash": "3195d87f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 01 KI Ueberblick Teil 1.pdf: 33 Seiten geladen\n",
      "✅ 01 KI Ueberblick Teil 2.pdf: 72 Seiten geladen\n",
      "✅ 02_Problemloesen_als_Suche.pdf: 35 Seiten geladen\n",
      "✅ 03 Machine Learning_exam.pdf: 48 Seiten geladen\n",
      "✅ 03 Machine Learning.pdf: 78 Seiten geladen\n",
      "✅ 03-1 Wissensrepraesentation.pdf: 11 Seiten geladen\n",
      "✅ 03-2_Aussagenlogik.pdf: 53 Seiten geladen\n",
      "✅ 03-3_Praedikatenlogik.pdf: 26 Seiten geladen\n",
      "✅ 05 Deep Learning_exam.pdf: 33 Seiten geladen\n",
      "✅ 05 Deep Learning.pdf: 39 Seiten geladen\n",
      "✅ 06 GenAI LLMs.pdf: 46 Seiten geladen\n",
      "\n",
      "📚 Insgesamt 474 Seiten aus 11 PDF-Dateien geladen.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader  \n",
    "from pathlib import Path\n",
    " \n",
    "pdf_dir = Path(\"data/pdfs\") #zeigt wo die PDFs gespeichert sind\n",
    " \n",
    "pdf_files = [\n",
    "    \"01 KI Ueberblick Teil 1.pdf\",\n",
    "    \"01 KI Ueberblick Teil 2.pdf\",\n",
    "    \"02_Problemloesen_als_Suche.pdf\",\n",
    "    \"03 Machine Learning_exam.pdf\",\n",
    "    \"03 Machine Learning.pdf\",\n",
    "    \"03-1 Wissensrepraesentation.pdf\",\n",
    "    \"03-2_Aussagenlogik.pdf\",\n",
    "    \"03-3_Praedikatenlogik.pdf\",\n",
    "    \"05 Deep Learning_exam.pdf\",\n",
    "    \"05 Deep Learning.pdf\",\n",
    "    \"06 GenAI LLMs.pdf\"\n",
    "]\n",
    "  \n",
    "# all_pages_pdf = []\n",
    "# for name in pdf_files:\n",
    "#     pdf_path = pdf_dir / name  \n",
    "#     if not pdf_path.exists():\n",
    "#         print(f\"Datei nicht gefunden: {pdf_path}\")\n",
    "#         continue\n",
    "#     loader = PyPDFLoader(str(pdf_path))\n",
    "#     pages = loader.load()\n",
    "#     all_pages_pdf.extend(pages)\n",
    " \n",
    "# print(f\"Loaded {len(all_pages_pdf)} pages from {len(pdf_files)} PDF documents.\")\n",
    " \n",
    "\n",
    "all_pages_pdf = []\n",
    "\n",
    "for name in pdf_files:\n",
    "    pdf_path = pdf_dir / name\n",
    "    if not pdf_path.exists():\n",
    "        print(f\"❌ Datei nicht gefunden: {pdf_path}\")\n",
    "        continue\n",
    "\n",
    "    loader = PyMuPDFLoader(str(pdf_path))\n",
    "    pages = loader.load()\n",
    "    all_pages_pdf.extend(pages)\n",
    "    print(f\"✅ {name}: {len(pages)} Seiten geladen\")\n",
    "\n",
    "print(f\"\\n📚 Insgesamt {len(all_pages_pdf)} Seiten aus {len(pdf_files)} PDF-Dateien geladen.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "a4a0f6c0e3844ca2a7e68192889aadf3",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758246179,
    "source_hash": "600011ae"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# get both websites and pdfs together\n",
    "all_docs = pages\n",
    "\n",
    "# define the splitter and strategy\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "splits = splitter.split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "c2e805c3427c4dcda39006a9105b2777",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758246229,
    "source_hash": "b0d5d671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial documents: 46\n",
      "Total chunks: 111\n",
      "Avg length: 225.4\n",
      "Min: 47, Max: 300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lengths = [len(s.page_content) for s in splits]\n",
    "print(f\"Initial documents: {len(all_docs)}\")\n",
    "print(f\"Total chunks: {len(splits)}\")\n",
    "print(f\"Avg length: {np.mean(lengths):.1f}\")\n",
    "print(f\"Min: {np.min(lengths)}, Max: {np.max(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "92e542040e284e96b3a342fcf5c63bc2",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 18668,
    "execution_start": 1759758246289,
    "source_hash": "cc8d3bbc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuel\\AppData\\Local\\Temp\\ipykernel_26236\\4293025327.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "276a8ec04dfa486a8eb26443f9c1b7f0",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 11559,
    "execution_start": 1759758265010,
    "source_hash": "65dc8a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e48ec05f-f220-499e-9a5c-2e37c083efd2',\n",
       " 'ffe6e2ec-2238-4594-b831-cd7b3b53dec7',\n",
       " 'a44770a8-547a-47c4-b251-7a86fbe851f6',\n",
       " 'e557b4b0-ded6-44e3-bcdb-0a4ea755071b',\n",
       " '0238679d-cbaf-4850-ae76-650be7b2b9f7',\n",
       " '43f365d3-9024-4a59-91b0-6dad31ae7c6d',\n",
       " 'eca20cf3-efd3-4318-8a2d-10e35754df43',\n",
       " '49a74535-31c5-4da4-aabe-9948f1303d5f',\n",
       " 'db0e2845-add3-4034-ae7c-24f76f136a51',\n",
       " 'f176e968-69bb-41be-b819-e5e7f5997f1e',\n",
       " '770cdf94-f441-49ac-8552-fa80696a5a11',\n",
       " 'a377399e-62e8-467e-8b73-d0e30e535eec',\n",
       " 'b8ced790-34af-4b04-84b7-eb06cca4e161',\n",
       " '3def7681-c420-45ff-9772-ede09c45476b',\n",
       " '8bd90d15-a1e1-4f2a-a37a-ee64cfc0ef3a',\n",
       " '83114681-1fed-4f75-a454-a36b005d57be',\n",
       " '6995032c-04f4-4e70-b2a8-3641824e4cc5',\n",
       " 'd6955563-fb13-421f-aad8-1f23b15ae385',\n",
       " '0481717c-b97b-448c-8dbd-ca54a2b6ca26',\n",
       " 'cf005615-ef59-4c06-bc4c-d2e71b4433c1',\n",
       " '5ce36508-53f3-4eef-905a-37cf2c8e4a7e',\n",
       " 'a5a5b5ca-ba6f-4c4b-9f8e-4801627a94f4',\n",
       " 'e5755230-1764-4c77-bf17-92a62903e9f0',\n",
       " '78b07d1f-f75f-4a76-b7ee-4236c92c4ade',\n",
       " '5b50a0ee-c65e-4906-9836-2786526d13af',\n",
       " 'cc463d51-13e0-499c-beb7-ac95ce4d3831',\n",
       " 'a552c196-5998-4228-833f-3f6979929529',\n",
       " 'bc774011-a1b1-45c9-ae34-77e3846c3fff',\n",
       " 'b94b765c-979a-4786-af57-25a4a556f0e6',\n",
       " '30907c32-52c7-4232-a563-2beeb95f4a7e',\n",
       " '759df878-78fd-4d9d-b7bc-c14cef0fe03e',\n",
       " '7a2f9c6d-fc84-4ebf-ae33-f34b0ad2b97e',\n",
       " 'e2b74610-fbc4-4276-9d6a-a91a8694f076',\n",
       " '3828c9e4-6f84-412c-8c5a-93c4ce941344',\n",
       " '14aa9668-ae8c-477a-b8c8-7a20a6510e7f',\n",
       " 'e80e2544-2616-49a5-8d0a-3abdce85e3f3',\n",
       " 'da72f6cc-5c78-4dbc-86c6-1427594f7e3e',\n",
       " 'd9528f6e-a85f-4ec9-a555-a52673dc9d25',\n",
       " 'aec9492d-10c0-46c2-a6c6-91085688cc04',\n",
       " 'b76379ab-288a-4304-8256-f148e8e6a1d0',\n",
       " '6a671922-4867-4047-8307-8fa2013672a7',\n",
       " 'cd08df7a-1c17-4976-9c29-7fb792ac639a',\n",
       " '90983354-5503-411b-8116-77bb4ad02d92',\n",
       " '0c9c253d-82fe-4b93-b2ff-917bfa9cdfe5',\n",
       " 'f89a5439-4bc8-47eb-bad1-cb676820ae54',\n",
       " 'bbc14778-ecb0-44b7-a173-5ef513015638',\n",
       " '247eeb6a-d4e8-4b43-a834-1e8e4a26ee1e',\n",
       " 'b7f0a7ba-7664-4329-8ba2-0050c563c5c1',\n",
       " '30b179ae-1a1f-44ab-8803-43960b4742c8',\n",
       " '1e80c058-4076-4ebd-8352-0fd9f18f9cab',\n",
       " 'c50e22d3-4a41-4af9-9418-9aa8a7ec372f',\n",
       " '2fcc218c-241e-462b-b400-37fb30aed476',\n",
       " 'a920e4e6-bd65-4b0e-bdce-efcabcdd48ec',\n",
       " '9b71efaa-8d6f-40ac-a898-fe77f82cd104',\n",
       " '5b5ae9d4-316c-4b1f-b4a2-36b19644005a',\n",
       " '9261025d-05bf-4069-b970-1639d9da489c',\n",
       " 'c142a5a0-cee6-4d0f-800d-d810c6678d7d',\n",
       " '7d4edc3d-640f-4ffb-a582-600e06122a31',\n",
       " '15507f16-a49b-49c0-81eb-1ce3773e2c27',\n",
       " '3250539f-8ea9-4c83-ab15-79643edb1f24',\n",
       " '7f79378a-9ddb-4915-af5c-04da16208ad9',\n",
       " '756ce95d-050b-4e5e-9fd7-6ed330a0ac0a',\n",
       " 'c10e0711-d69e-4ad8-bcfe-c064c41dc84d',\n",
       " '6d2f7b73-bc21-4394-9dab-8be237710ade',\n",
       " '0e4e3262-af4a-4488-92ad-7ca41754697b',\n",
       " 'eac4712a-3c18-446d-817e-1050d996942b',\n",
       " '78a55b98-cfd2-45ca-ae40-515ad7180dce',\n",
       " '65c50bb9-a0e7-46a5-82a3-1d32c74d67fb',\n",
       " '6de733d4-e6c2-496b-9d80-bd5c7f686de4',\n",
       " '76788749-943b-44bc-bc21-fb301ed67fa4',\n",
       " '8522b83b-a8d9-4cf3-9220-bc9041238ea8',\n",
       " '5a8e5d41-40b6-40ad-9dd7-5dfe91290394',\n",
       " '6101a569-af60-4dac-8a49-b12f14529d41',\n",
       " '9f293a23-5b36-456f-9250-d204d8d419f4',\n",
       " 'f6ee447f-54b0-4847-a77d-bfe7ec5a83ac',\n",
       " 'e6ebc20c-48ff-4b59-be4d-32ee7454fe26',\n",
       " 'ebcdc45d-a86a-44d1-96e4-3e755bd3c6f4',\n",
       " '2544b484-fcf1-4fbb-8206-ca61a3ac8429',\n",
       " '4c19ea45-78a6-4076-9185-11b0a7e3529e',\n",
       " '0a1055d9-aa4c-47af-985d-894064dc41db',\n",
       " 'cbc67fe8-9be2-4677-840d-a5928b727b32',\n",
       " '6f6ac946-a3b5-4e34-bb68-a7af23c83350',\n",
       " 'd4c417f1-cfa2-44c8-a933-43111dc08538',\n",
       " '69489c86-eeb7-4f90-8018-c80962dc616b',\n",
       " '43617aa4-78ac-479d-8776-59a1680b30ed',\n",
       " '0a599328-e221-4253-8a0e-8aca1e0a9492',\n",
       " 'c8ba009d-c733-4607-b484-c5b005414087',\n",
       " 'e2aeeb6c-bac7-483e-b0a2-55df0769d043',\n",
       " 'f1210cf1-ed80-4fc0-958c-6ef4f3957e6f',\n",
       " '2c77706c-7197-4773-ac93-20272dc915a9',\n",
       " '98f8b259-c3c0-4f41-a168-bb5fbc118fc0',\n",
       " 'fbe3d6b7-595d-4a73-b460-d26c1584f371',\n",
       " '6ba1b1a8-e925-47c2-9504-e02a3c9accb9',\n",
       " 'fb4e3b3e-80dc-41fa-8da2-88e3a732bf39',\n",
       " '13b02c7d-18fe-4670-91e8-13e487b06592',\n",
       " '3026c53e-9580-47a6-a3e4-29f34cd0b9d0',\n",
       " '80469ed6-0a37-43b4-85b9-5628bc8d6d7c',\n",
       " '32798fce-642f-4816-a4e6-7d1584e675b3',\n",
       " '488c7a01-e5fb-4c0f-a466-1fe703b31f71',\n",
       " '5612ca60-ba29-4eb1-8f0c-8c71bd9f5ba3',\n",
       " '2efe8612-8085-4d9a-a293-08e4e0605872',\n",
       " 'e9d8ccb6-c67a-4cfc-b233-e846bc4d61fc',\n",
       " '5ed156d2-e196-4494-a809-a0eceb714df1',\n",
       " '33c89543-0801-45f2-948b-4e4e56103114',\n",
       " '7f3d2cb9-463c-42b2-9bef-9332a1048cce',\n",
       " '569654e5-3714-4bb9-9eee-7765b07d5a94',\n",
       " '85942b89-2d84-439b-a6b3-afe80c434b81',\n",
       " '421fdfdc-b40a-40b4-8c24-f6f949eb4c77',\n",
       " 'b1420b23-ce72-48ed-b380-95d1470d6b75',\n",
       " '8544e076-509a-493f-a671-5ff0655b6c09',\n",
       " '70de468d-d993-4978-aeb2-6bb73038cad8']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding_dim = len(embeddings.embed_query(\"hello world\"))\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    "    normalize_L2=True\n",
    ")\n",
    "\n",
    "vector_store.add_documents(documents=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "39c71595501b4099b86a137eecf48618",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758276629,
    "source_hash": "2ca0bc3c"
   },
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "dca3c25d995f4dcaa99e9e38d24247c9",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 1,
    "execution_start": 1759758276689,
    "source_hash": "aa4529ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieved doc 1 ---\n",
      "w  d n.\n",
      "– I  B   ich d   Bildv  a   itung w  d n s lch  \n",
      "M d ll   ü  Au ga  n wi  Bildklassi izi  ung,\n",
      "O j kt  k nnung  d   Bildg n  i  ung  ing s tzt.\n",
      "– In d   Audi v  a   itung  ind n sich \n",
      "Anw ndung n in Sp ach  k nnung, \n",
      "Musikk  p siti n  d   S undanalys . ...\n",
      "\n",
      "--- Retrieved doc 2 ---\n",
      "Prof. Dr. Manuel Renold\n",
      "Was ist in LLMs drin?\n",
      "GenAI & LLMs\n",
      "28\n",
      "Bild: https://lifearchitect.ai/whats-in-my-ai/ ...\n",
      "\n",
      "--- Retrieved doc 3 ---\n",
      "Prof. Dr. Manuel Renold\n",
      "– T  p  atu : R guli  t di  Zu älligk it d   Antw  t n  in s Sp ach  d lls.\n",
      "– Ein luss: Höh    W  t    höh n di  Vi l alt, ni d ig    W  t  s  g n  ü  V  h  s h a k it.\n",
      "– Anpassung: Einst ll a , u  K  ativität  d   P äzisi n zu st ig  n.\n",
      "P   pt Engin   ing: T  p  atu ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuel\\AppData\\Local\\Temp\\ipykernel_26236\\2010197779.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(\"Prädikatenlogik\")\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"Prädikatenlogik\")\n",
    "for i, d in enumerate(docs, 1):\n",
    "    print(f\"--- Retrieved doc {i} ---\")\n",
    "    print(d.page_content[:400], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "7628494db79b4133966fb98d4c707ab8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "chain = (\n",
    "{\n",
    "    \"context\": retriever,\n",
    "    \"question\": RunnablePassthrough(),\n",
    "}\n",
    "    | LERNASSISTENT_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "51912f3cb08b43e4b9d485e1821e52ce",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 25790,
    "execution_start": 1759758276799,
    "source_hash": "51d1e9bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dazu habe ich im bereitgestellten Material nichts.  \n",
      "Bitte laden Sie die Folie oder den Abschnitt hoch, in dem Prädikatenlogik behandelt wird (z. B. Titel / Seite / Kapitel).\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# USER_PROMPT=\"Generiere mir einen Post für die PubTour am 16. Oktober\"\n",
    "\n",
    "# result = chain.invoke(\"Generiere mir einen Post für die PubTour am 16. Oktober\")\n",
    "# print(result)\n",
    "\n",
    "result = chain.invoke(\"Was ist Prädikatenlogik?\")\n",
    "print(result)\n",
    "\n",
    "#result = chain.invoke(user_prompt)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer(question: str) -> str:\n",
    "    # Kein LangSmith, einfach direkt die Chain ausführen\n",
    "    try:\n",
    "        response = chain.invoke(question)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Fehler bei der Verarbeitung: {e}\"\n",
    "\n",
    "# --- Gradio UI ---\n",
    "demo = gr.Interface(\n",
    "    fn=answer,\n",
    "    inputs=gr.Textbox(label=\"Question\", placeholder=\"Type your question here...\"),\n",
    "    outputs=gr.Textbox(label=\"Answer\", lines=10),\n",
    "    title=\"Lernassistent BAI\",\n",
    "    description=\"Stelle Fragen zum Lernstoff der BAI und erhalte präzise, prüfungsrelevante Antworten.\",\n",
    ")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=56a0a349-7f2e-43e5-8d52-5ded467f6e9c' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "b03039a6aad547a39dea08ca00c7302d",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
