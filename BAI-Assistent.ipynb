{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "13645a6401094b8e9e43ee6439cebbb7",
    "deepnote_cell_type": "markdown"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "71dc5b3cd80f444c85229c5a5d134243",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "# BAI-Assistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8e372a10361b49d79135bb1ac2bc94e8",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "Grundidee: Hilft bei der Erstellung von Zusammenfassungen, welche auf Basis unseren Zusammenfassungen und Vorlesungsfolien die Antworten generiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "34e39c6b71ff43369582549ea792d7a4",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "#### Unsere Problemstellung\n",
    "Während der Prüfungsvorbereitung sind vor allem Erstsemester Studenten überfordert, wie man beim Lernen vorgehen kann. Daher haben wir es als Lücke vor allem im BAI-Studiengang erkannt.\n",
    "\n",
    "#### Use Cases: \n",
    "Ich möchte, dass mir der Lernassistent mir Fachbegriffe in ML und Einführung KI erklärt\n",
    "Ich möchte gut auf die Prüfungen durch den Lernassistenten vorbereitet werden\n",
    "-\tIch möchte Prüfungsfragen erhalten\n",
    "-\tIch möchte, dass es Merksätze gibt\n",
    "-\tIch möchte, dass die Erklärungen einfach sind\n",
    "-\tIch möchte Hilfe/Beratung erhalten, wie ich mein Cheat Sheet gemäss Stoffabgrenzung aufstellen kann\n",
    "Ich möchte schnelle und unlimitierte Antworten\n",
    "(Ich möchte Prüfungsfragen vom Chatbot erhalten, damit ich mich gut auf die Prüfung vorbereiten kann)\n",
    "\n",
    "##### Zielgruppe: \n",
    "BAI-Studenten im ersten Studienjahr, die Maschinelles Lernen und Einführung in die Künstliche Intelligenz belegen\n",
    "\n",
    "##### KPIs: \n",
    "•\tAntwortzeit < 5 Sekunden\n",
    "•\tPrüfungsnutzen > 70 % finden Quiz hilfreich\n",
    "•\tFachliche Korrektheit >85%\n",
    "\n",
    "Unsere Erwartungen: Fachbegriffe fragen, Unterschied zwischen Supervised und Unsupervised Learning, Was ist One Hot Encoding\n",
    "Inhalte für den KI-Assistenten: Folien Unterricht, Zusammenfassungen, Stoffabgrenzung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zusammenführung LLM und API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sende Test-Ping...\n",
      "Antworttyp: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Inhalt: pong\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Stelle sicher, dass dieser Key existiert ---\n",
    "assert \"GROQ_API_KEY_BAI\" in os.environ, \"GROQ_API_KEY fehlt in den Env Vars!\"\n",
    "\n",
    "# --- Initialisiere LLM explizit für OpenRouter ---\n",
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-oss-120b\",   \n",
    "    api_key=os.environ[\"GROQ_API_KEY_BAI\"],\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "print(\"Sende Test-Ping...\")\n",
    "try:\n",
    "    msg = llm.invoke(\"Sag exakt: pong\")\n",
    "    print(\"Antworttyp:\", type(msg))\n",
    "    # msg ist i.d.R. ein AIMessage – gib Inhalt sicher aus:\n",
    "    print(\"Inhalt:\", getattr(msg, \"content\", msg))\n",
    "except Exception as e:\n",
    "    print(\"FEHLER beim LLM-Aufruf:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "48703dda10da4a189aae9e8b27d1da51",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 1312,
    "execution_start": 1759758229079,
    "source_hash": "af9e9b5a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "#LLM_MODEL = \"openai/gpt-oss-20b:free\"\n",
    "LLM_MODEL = \"openai/gpt-oss-120b\"\n",
    "LLM_TEMPERATURE = 0.4\n",
    "BASE_URL = \"https://api.groq.com/openai/v1\"\n",
    "OPENROUTER_API_KEY = os.getenv(\"GROQ_API_KEY_BAI\")\n",
    "USER_PROMPT=\"Ich verstehe GenAI nicht, kannst du das mir einfach erklären?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "560a2f48c30445d0af462bee57df506a",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 2680,
    "execution_start": 1759758230441,
    "source_hash": "b9f7f98b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_MODEL,\n",
    "    temperature=LLM_TEMPERATURE,\n",
    "    base_url=BASE_URL,\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "print(type(llm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kurz sicherstellen, ob API Key funktioniert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pong\n",
      "False None\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(llm.invoke(\"Sag nur: pong\").content)\n",
    "except Exception as e:\n",
    "    print(repr(e))\n",
    "\n",
    "# Test 2: Env-Variablen sichtbar?\n",
    "import os\n",
    "print(\"OPENAI_API_KEY\" in os.environ, os.environ.get(\"OPENAI_BASE_URL\"))\n",
    "print(\"GROQ_API_KEY_BAI\" in os.environ)\n",
    "print(\"OPENROUTER_API_KEY\" in os.environ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatPrompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "a39ea2f0cef040f4bc860ac3c41a6a4d",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758233169,
    "source_hash": "90dbf177"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "FWO_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"Du bist der FWO-Assistent (Fachschaft Wirtschaft Olten, FHNW). \"\n",
    "     \"Bevor du schreibst, beziehst du dich IMMER auf: \"\n",
    "     \"1) Kampagnenkonzept (Ziel, Kernbotschaft, Mehrwert) \"\n",
    "     \"2) Redaktionsplan (Phase, wiederkehrende Formate, Timing). \"\n",
    "     \"Vermeide Genderung und gebrauche bspw. Lehrperson anstatt Lehrer*innen \"\n",
    "     \"Generiere jeweils immer zwei Vorschläge zu jeder Plattform (Instagram, WhatsApp, LinkedIn)\"\n",
    "     \"Vermeide Floskeln, schreibe aktiv und konkret.\"\n",
    "     \"If you are unsure or the answer isn't in the context, say that you don't know.\\n\\n\"\n",
    "     \"CONTEXT: \\n {context}\"\n",
    "    ),\n",
    "    (\"human\",\"{question}\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "2f723a65eeb04432a1ba77dcfe049109",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 483,
    "execution_start": 1759758245649,
    "source_hash": "3195d87f"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File path Order pdf/SoMe Konzept.pdf is not a valid file or url",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# List of PDF file paths\u001b[39;00m\n\u001b[32m      5\u001b[39m pdf_path = \u001b[33m\"\u001b[39m\u001b[33mOrder pdf/SoMe Konzept.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m loader = \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m pages = loader.load()\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Load all documents\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# all_pages_pdf = []\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# for pdf in pdf_files:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m#print(f\"Loaded {len(all_pages_pdf)} pages from {len(pdf_files)} pdf documents.\")\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\.vscode\\KIBAIAssistent\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:281\u001b[39m, in \u001b[36mPyPDFLoader.__init__\u001b[39m\u001b[34m(self, file_path, password, headers, extract_images, mode, images_parser, images_inner_format, pages_delimiter, extraction_mode, extraction_kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    239\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    240\u001b[39m     file_path: Union[\u001b[38;5;28mstr\u001b[39m, PurePath],\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m     extraction_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    251\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    252\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize with a file path.\u001b[39;00m\n\u001b[32m    253\u001b[39m \n\u001b[32m    254\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m \u001b[33;03m        `aload` methods to retrieve parsed documents with content and metadata.\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28mself\u001b[39m.parser = PyPDFParser(\n\u001b[32m    283\u001b[39m         password=password,\n\u001b[32m    284\u001b[39m         mode=mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    290\u001b[39m         extraction_kwargs=extraction_kwargs,\n\u001b[32m    291\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\.vscode\\KIBAIAssistent\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:140\u001b[39m, in \u001b[36mBasePDFLoader.__init__\u001b[39m\u001b[34m(self, file_path, headers)\u001b[39m\n\u001b[32m    138\u001b[39m         \u001b[38;5;28mself\u001b[39m.file_path = \u001b[38;5;28mstr\u001b[39m(temp_pdf)\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(\u001b[38;5;28mself\u001b[39m.file_path):\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFile path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is not a valid file or url\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m.file_path)\n",
      "\u001b[31mValueError\u001b[39m: File path Order pdf/SoMe Konzept.pdf is not a valid file or url"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# List of PDF file paths\n",
    "\n",
    "pdf_path = \"Order pdf/SoMe Konzept.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(str(pdf_path))\n",
    "pages = loader.load()\n",
    "\n",
    "\n",
    "# Load all documents\n",
    "# all_pages_pdf = []\n",
    "# for pdf in pdf_files:\n",
    "#     loader = PyPDFLoader(pdf)\n",
    "#     pages = loader.load()\n",
    "#     all_pages_pdf.extend(pages)\n",
    "\n",
    "#print(f\"Loaded {len(all_pages_pdf)} pages from {len(pdf_files)} pdf documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a4a0f6c0e3844ca2a7e68192889aadf3",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758246179,
    "source_hash": "600011ae"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# get both websites and pdfs together\n",
    "all_docs = pages\n",
    "\n",
    "# define the splitter and strategy\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "splits = splitter.split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c2e805c3427c4dcda39006a9105b2777",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758246229,
    "source_hash": "b0d5d671"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lengths = [len(s.page_content) for s in splits]\n",
    "print(f\"Initial documents: {len(all_docs)}\")\n",
    "print(f\"Total chunks: {len(splits)}\")\n",
    "print(f\"Avg length: {np.mean(lengths):.1f}\")\n",
    "print(f\"Min: {np.min(lengths)}, Max: {np.max(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "92e542040e284e96b3a342fcf5c63bc2",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 18668,
    "execution_start": 1759758246289,
    "source_hash": "cc8d3bbc"
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "276a8ec04dfa486a8eb26443f9c1b7f0",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 11559,
    "execution_start": 1759758265010,
    "source_hash": "65dc8a79"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding_dim = len(embeddings.embed_query(\"hello world\"))\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    "    normalize_L2=True\n",
    ")\n",
    "\n",
    "vector_store.add_documents(documents=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "39c71595501b4099b86a137eecf48618",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758276629,
    "source_hash": "2ca0bc3c"
   },
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "dca3c25d995f4dcaa99e9e38d24247c9",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 1,
    "execution_start": 1759758276689,
    "source_hash": "aa4529ad"
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"Hashtags für Instagram\")\n",
    "for i, d in enumerate(docs, 1):\n",
    "    print(f\"--- Retrieved doc {i} ---\")\n",
    "    print(d.page_content[:400], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7628494db79b4133966fb98d4c707ab8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# chain = (\n",
    "#     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "#     | FWO_PROMPT\n",
    "#     | llm\n",
    "#     | output_parser\n",
    "# )\n",
    "\n",
    "chain = (\n",
    "{\n",
    "    \"context\": retriever,\n",
    "    \"question\": RunnablePassthrough(),\n",
    "}\n",
    "    | FWO_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "51912f3cb08b43e4b9d485e1821e52ce",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 25790,
    "execution_start": 1759758276799,
    "source_hash": "51d1e9bd"
   },
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# USER_PROMPT=\"Generiere mir einen Post für die PubTour am 16. Oktober\"\n",
    "\n",
    "# result = chain.invoke(\"Generiere mir einen Post für die PubTour am 16. Oktober\")\n",
    "# print(result)\n",
    "\n",
    "result = chain.invoke(\"Generiere mir einen Post für die PubTour am 16. Oktober\")\n",
    "print(result)\n",
    "\n",
    "#result = chain.invoke(user_prompt)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer(question: str) -> str:\n",
    "    # Kein LangSmith, einfach direkt die Chain ausführen\n",
    "    try:\n",
    "        response = chain.invoke(question)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Fehler bei der Verarbeitung: {e}\"\n",
    "\n",
    "# --- Gradio UI ---\n",
    "demo = gr.Interface(\n",
    "    fn=answer,\n",
    "    inputs=gr.Textbox(label=\"Question\", placeholder=\"Type your question here...\"),\n",
    "    outputs=gr.Textbox(label=\"Answer\", lines=10),\n",
    "    title=\"FWO Chatbot\",\n",
    "    description=\"Write a social media post based on the context provided.\",\n",
    ")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=56a0a349-7f2e-43e5-8d52-5ded467f6e9c' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "b03039a6aad547a39dea08ca00c7302d",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
