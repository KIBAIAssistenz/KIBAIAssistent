{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "13645a6401094b8e9e43ee6439cebbb7",
    "deepnote_cell_type": "markdown"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "71dc5b3cd80f444c85229c5a5d134243",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "# BAI-Assistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8e372a10361b49d79135bb1ac2bc94e8",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "Grundidee: Hilft bei der Erstellung von Zusammenfassungen, welche auf Basis unseren Zusammenfassungen und Vorlesungsfolien die Antworten generiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "34e39c6b71ff43369582549ea792d7a4",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "#### Unsere Problemstellung\n",
    "W√§hrend der Pr√ºfungsvorbereitung sind vor allem Erstsemester Studenten √ºberfordert, wie man beim Lernen vorgehen kann. Daher haben wir es als L√ºcke vor allem im BAI-Studiengang erkannt.\n",
    "\n",
    "#### Use Cases: \n",
    "Ich m√∂chte, dass mir der Lernassistent mir Fachbegriffe in ML und Einf√ºhrung KI erkl√§rt\n",
    "Ich m√∂chte gut auf die Pr√ºfungen durch den Lernassistenten vorbereitet werden\n",
    "-\tIch m√∂chte Pr√ºfungsfragen erhalten\n",
    "-\tIch m√∂chte, dass es Merks√§tze gibt\n",
    "-\tIch m√∂chte, dass die Erkl√§rungen einfach sind\n",
    "-\tIch m√∂chte Hilfe/Beratung erhalten, wie ich mein Cheat Sheet gem√§ss Stoffabgrenzung aufstellen kann\n",
    "Ich m√∂chte schnelle und unlimitierte Antworten\n",
    "(Ich m√∂chte Pr√ºfungsfragen vom Chatbot erhalten, damit ich mich gut auf die Pr√ºfung vorbereiten kann)\n",
    "\n",
    "##### Zielgruppe: \n",
    "BAI-Studenten im ersten Studienjahr, die Maschinelles Lernen und Einf√ºhrung in die K√ºnstliche Intelligenz belegen\n",
    "\n",
    "##### KPIs: \n",
    "‚Ä¢\tAntwortzeit < 5 Sekunden\n",
    "‚Ä¢\tPr√ºfungsnutzen > 70 % finden Quiz hilfreich\n",
    "‚Ä¢\tFachliche Korrektheit >85%\n",
    "\n",
    "Unsere Erwartungen: Fachbegriffe fragen, Unterschied zwischen Supervised und Unsupervised Learning, Was ist One Hot Encoding\n",
    "Inhalte f√ºr den KI-Assistenten: Folien Unterricht, Zusammenfassungen, Stoffabgrenzung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zusammenf√ºhrung LLM und API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sende Test-Ping...\n",
      "Antworttyp: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Inhalt: pong\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Stelle sicher, dass dieser Key existiert ---\n",
    "assert \"GROQ_API_KEY_BAI\" in os.environ, \"GROQ_API_KEY fehlt in den Env Vars!\"\n",
    "\n",
    "# --- Initialisiere LLM explizit f√ºr OpenRouter ---\n",
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-oss-120b\",   \n",
    "    api_key=os.environ[\"GROQ_API_KEY_BAI\"],\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "print(\"Sende Test-Ping...\")\n",
    "try:\n",
    "    msg = llm.invoke(\"Sag exakt: pong\")\n",
    "    print(\"Antworttyp:\", type(msg))\n",
    "    # msg ist i.d.R. ein AIMessage ‚Äì gib Inhalt sicher aus:\n",
    "    print(\"Inhalt:\", getattr(msg, \"content\", msg))\n",
    "except Exception as e:\n",
    "    print(\"FEHLER beim LLM-Aufruf:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "48703dda10da4a189aae9e8b27d1da51",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 1312,
    "execution_start": 1759758229079,
    "source_hash": "af9e9b5a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "#LLM_MODEL = \"openai/gpt-oss-20b:free\"\n",
    "LLM_MODEL = \"openai/gpt-oss-120b\"\n",
    "LLM_TEMPERATURE = 0.4\n",
    "BASE_URL = \"https://api.groq.com/openai/v1\"\n",
    "OPENROUTER_API_KEY = os.getenv(\"GROQ_API_KEY_BAI\")\n",
    "USER_PROMPT=\"Ich verstehe GenAI nicht, kannst du das mir einfach erkl√§ren?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "560a2f48c30445d0af462bee57df506a",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 2680,
    "execution_start": 1759758230441,
    "source_hash": "b9f7f98b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_MODEL,\n",
    "    temperature=LLM_TEMPERATURE,\n",
    "    base_url=BASE_URL,\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "print(type(llm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kurz sicherstellen, ob API Key funktioniert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pong\n",
      "False None\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(llm.invoke(\"Sag nur: pong\").content)\n",
    "except Exception as e:\n",
    "    print(repr(e))\n",
    "\n",
    "# Test 2: Env-Variablen sichtbar?\n",
    "import os\n",
    "print(\"OPENAI_API_KEY\" in os.environ, os.environ.get(\"OPENAI_BASE_URL\"))\n",
    "print(\"GROQ_API_KEY_BAI\" in os.environ)\n",
    "print(\"OPENROUTER_API_KEY\" in os.environ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatPrompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "a39ea2f0cef040f4bc860ac3c41a6a4d",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758233169,
    "source_hash": "90dbf177"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    " \n",
    "LERNASSISTENT_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        (\n",
    "            \"Sprache: Deutsch. Rolle: FHNW-BAI-Lernassistent; erkl√§re wie eine geduldige Lehrperson.\\n\"\n",
    "            \"Nutze AUSSCHLIESSLICH den bereitgestellten CONTEXT (Folien/Skripte).\\n\"\n",
    "            \"Wenn Informationen fehlen oder die Frage nicht im CONTEXT abgedeckt ist, antworte exakt:\\n\"\n",
    "            \"\\\"Dazu habe ich im bereitgestellten Material nichts.\\\" \\n\"\n",
    "            \"Schlage danach pr√§zise n√§chste Schritte vor (z. B. welche Folie/Abschnitt hochzuladen w√§re).\\n\"\n",
    "            \"Ziel: Studierende effizient auf Pr√ºfungen vorbereiten.\\n\"\n",
    "            \"Stil: aktiv, konkret, ohne Floskeln, keine Gender-Sonderzeichen (nutze z. B. 'Lehrperson').\\n\"\n",
    "            \"Gib GENAU EINEN L√∂sungsvorschlag und EIN einfaches Beispiel.\\n\"\n",
    "            \"Halte dich an Terminologie aus dem CONTEXT. Keine externen Fakten, keine Spekulation.\\n\"\n",
    "            \"CONTEXT:\\n{context}\"\n",
    "        )\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        (\n",
    "            \"FRAGE: {question}\\n\"\n",
    "            \"Erstelle die Antwort in genau dieser Struktur:\\n\"\n",
    "            \"1) Kurzantwort (2‚Äì3 S√§tze, pr√ºfungsrelevant)\\n\"\n",
    "            \"2) Erkl√§rung (max. 8 S√§tze, schrittweise, mit Intuition)\\n\"\n",
    "            \"3) Beispiel (sehr einfach, kleine Zahlen/konkreter Mini-Fall)\\n\"\n",
    "            \"4) Typische Pr√ºfungsfehler (Bullets)\\n\"\n",
    "            \"5) Verst√§ndnis-Check (1‚Äì2 Kontrollfragen)\\n\"\n",
    "            \"6) Quellen (Dokumenttitel + Seiten/Abschnitt aus CONTEXT)\"\n",
    "        )\n",
    "    ),\n",
    "])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "2f723a65eeb04432a1ba77dcfe049109",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 483,
    "execution_start": 1759758245649,
    "source_hash": "3195d87f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 01 KI Ueberblick Teil 1.pdf: 33 Seiten geladen\n",
      "‚úÖ 01 KI Ueberblick Teil 2.pdf: 72 Seiten geladen\n",
      "‚úÖ 02_Problemloesen_als_Suche.pdf: 35 Seiten geladen\n",
      "‚úÖ 03 Machine Learning_exam.pdf: 48 Seiten geladen\n",
      "‚úÖ 03 Machine Learning.pdf: 78 Seiten geladen\n",
      "‚úÖ 03-1 Wissensrepraesentation.pdf: 11 Seiten geladen\n",
      "‚úÖ 03-2_Aussagenlogik.pdf: 53 Seiten geladen\n",
      "‚úÖ 03-3_Praedikatenlogik.pdf: 26 Seiten geladen\n",
      "‚úÖ 05 Deep Learning_exam.pdf: 33 Seiten geladen\n",
      "‚úÖ 05 Deep Learning.pdf: 39 Seiten geladen\n",
      "‚úÖ 06 GenAI LLMs.pdf: 46 Seiten geladen\n",
      "\n",
      "üìö Insgesamt 474 Seiten aus 11 PDF-Dateien geladen.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader  \n",
    "from pathlib import Path\n",
    " \n",
    "pdf_dir = Path(\"data/pdfs\") #zeigt wo die PDFs gespeichert sind\n",
    " \n",
    "pdf_files = [\n",
    "    \"01 KI Ueberblick Teil 1.pdf\",\n",
    "    \"01 KI Ueberblick Teil 2.pdf\",\n",
    "    \"02_Problemloesen_als_Suche.pdf\",\n",
    "    \"03 Machine Learning_exam.pdf\",\n",
    "    \"03 Machine Learning.pdf\",\n",
    "    \"03-1 Wissensrepraesentation.pdf\",\n",
    "    \"03-2_Aussagenlogik.pdf\",\n",
    "    \"03-3_Praedikatenlogik.pdf\",\n",
    "    \"05 Deep Learning_exam.pdf\",\n",
    "    \"05 Deep Learning.pdf\",\n",
    "    \"06 GenAI LLMs.pdf\"\n",
    "]\n",
    "  \n",
    "# all_pages_pdf = []\n",
    "# for name in pdf_files:\n",
    "#     pdf_path = pdf_dir / name  \n",
    "#     if not pdf_path.exists():\n",
    "#         print(f\"Datei nicht gefunden: {pdf_path}\")\n",
    "#         continue\n",
    "#     loader = PyPDFLoader(str(pdf_path))\n",
    "#     pages = loader.load()\n",
    "#     all_pages_pdf.extend(pages)\n",
    " \n",
    "# print(f\"Loaded {len(all_pages_pdf)} pages from {len(pdf_files)} PDF documents.\")\n",
    " \n",
    "\n",
    "all_pages_pdf = []\n",
    "\n",
    "for name in pdf_files:\n",
    "    pdf_path = pdf_dir / name\n",
    "    if not pdf_path.exists():\n",
    "        print(f\"‚ùå Datei nicht gefunden: {pdf_path}\")\n",
    "        continue\n",
    "\n",
    "    loader = PyMuPDFLoader(str(pdf_path))\n",
    "    pages = loader.load()\n",
    "    all_pages_pdf.extend(pages)\n",
    "    print(f\"‚úÖ {name}: {len(pages)} Seiten geladen\")\n",
    "\n",
    "print(f\"\\nüìö Insgesamt {len(all_pages_pdf)} Seiten aus {len(pdf_files)} PDF-Dateien geladen.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "a4a0f6c0e3844ca2a7e68192889aadf3",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758246179,
    "source_hash": "600011ae"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# get both websites and pdfs together\n",
    "all_docs = pages\n",
    "\n",
    "# define the splitter and strategy\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "splits = splitter.split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "c2e805c3427c4dcda39006a9105b2777",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758246229,
    "source_hash": "b0d5d671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial documents: 46\n",
      "Total chunks: 111\n",
      "Avg length: 225.4\n",
      "Min: 47, Max: 300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lengths = [len(s.page_content) for s in splits]\n",
    "print(f\"Initial documents: {len(all_docs)}\")\n",
    "print(f\"Total chunks: {len(splits)}\")\n",
    "print(f\"Avg length: {np.mean(lengths):.1f}\")\n",
    "print(f\"Min: {np.min(lengths)}, Max: {np.max(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "92e542040e284e96b3a342fcf5c63bc2",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 18668,
    "execution_start": 1759758246289,
    "source_hash": "cc8d3bbc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuel\\AppData\\Local\\Temp\\ipykernel_26236\\4293025327.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "276a8ec04dfa486a8eb26443f9c1b7f0",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 11559,
    "execution_start": 1759758265010,
    "source_hash": "65dc8a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e48ec05f-f220-499e-9a5c-2e37c083efd2',\n",
       " 'ffe6e2ec-2238-4594-b831-cd7b3b53dec7',\n",
       " 'a44770a8-547a-47c4-b251-7a86fbe851f6',\n",
       " 'e557b4b0-ded6-44e3-bcdb-0a4ea755071b',\n",
       " '0238679d-cbaf-4850-ae76-650be7b2b9f7',\n",
       " '43f365d3-9024-4a59-91b0-6dad31ae7c6d',\n",
       " 'eca20cf3-efd3-4318-8a2d-10e35754df43',\n",
       " '49a74535-31c5-4da4-aabe-9948f1303d5f',\n",
       " 'db0e2845-add3-4034-ae7c-24f76f136a51',\n",
       " 'f176e968-69bb-41be-b819-e5e7f5997f1e',\n",
       " '770cdf94-f441-49ac-8552-fa80696a5a11',\n",
       " 'a377399e-62e8-467e-8b73-d0e30e535eec',\n",
       " 'b8ced790-34af-4b04-84b7-eb06cca4e161',\n",
       " '3def7681-c420-45ff-9772-ede09c45476b',\n",
       " '8bd90d15-a1e1-4f2a-a37a-ee64cfc0ef3a',\n",
       " '83114681-1fed-4f75-a454-a36b005d57be',\n",
       " '6995032c-04f4-4e70-b2a8-3641824e4cc5',\n",
       " 'd6955563-fb13-421f-aad8-1f23b15ae385',\n",
       " '0481717c-b97b-448c-8dbd-ca54a2b6ca26',\n",
       " 'cf005615-ef59-4c06-bc4c-d2e71b4433c1',\n",
       " '5ce36508-53f3-4eef-905a-37cf2c8e4a7e',\n",
       " 'a5a5b5ca-ba6f-4c4b-9f8e-4801627a94f4',\n",
       " 'e5755230-1764-4c77-bf17-92a62903e9f0',\n",
       " '78b07d1f-f75f-4a76-b7ee-4236c92c4ade',\n",
       " '5b50a0ee-c65e-4906-9836-2786526d13af',\n",
       " 'cc463d51-13e0-499c-beb7-ac95ce4d3831',\n",
       " 'a552c196-5998-4228-833f-3f6979929529',\n",
       " 'bc774011-a1b1-45c9-ae34-77e3846c3fff',\n",
       " 'b94b765c-979a-4786-af57-25a4a556f0e6',\n",
       " '30907c32-52c7-4232-a563-2beeb95f4a7e',\n",
       " '759df878-78fd-4d9d-b7bc-c14cef0fe03e',\n",
       " '7a2f9c6d-fc84-4ebf-ae33-f34b0ad2b97e',\n",
       " 'e2b74610-fbc4-4276-9d6a-a91a8694f076',\n",
       " '3828c9e4-6f84-412c-8c5a-93c4ce941344',\n",
       " '14aa9668-ae8c-477a-b8c8-7a20a6510e7f',\n",
       " 'e80e2544-2616-49a5-8d0a-3abdce85e3f3',\n",
       " 'da72f6cc-5c78-4dbc-86c6-1427594f7e3e',\n",
       " 'd9528f6e-a85f-4ec9-a555-a52673dc9d25',\n",
       " 'aec9492d-10c0-46c2-a6c6-91085688cc04',\n",
       " 'b76379ab-288a-4304-8256-f148e8e6a1d0',\n",
       " '6a671922-4867-4047-8307-8fa2013672a7',\n",
       " 'cd08df7a-1c17-4976-9c29-7fb792ac639a',\n",
       " '90983354-5503-411b-8116-77bb4ad02d92',\n",
       " '0c9c253d-82fe-4b93-b2ff-917bfa9cdfe5',\n",
       " 'f89a5439-4bc8-47eb-bad1-cb676820ae54',\n",
       " 'bbc14778-ecb0-44b7-a173-5ef513015638',\n",
       " '247eeb6a-d4e8-4b43-a834-1e8e4a26ee1e',\n",
       " 'b7f0a7ba-7664-4329-8ba2-0050c563c5c1',\n",
       " '30b179ae-1a1f-44ab-8803-43960b4742c8',\n",
       " '1e80c058-4076-4ebd-8352-0fd9f18f9cab',\n",
       " 'c50e22d3-4a41-4af9-9418-9aa8a7ec372f',\n",
       " '2fcc218c-241e-462b-b400-37fb30aed476',\n",
       " 'a920e4e6-bd65-4b0e-bdce-efcabcdd48ec',\n",
       " '9b71efaa-8d6f-40ac-a898-fe77f82cd104',\n",
       " '5b5ae9d4-316c-4b1f-b4a2-36b19644005a',\n",
       " '9261025d-05bf-4069-b970-1639d9da489c',\n",
       " 'c142a5a0-cee6-4d0f-800d-d810c6678d7d',\n",
       " '7d4edc3d-640f-4ffb-a582-600e06122a31',\n",
       " '15507f16-a49b-49c0-81eb-1ce3773e2c27',\n",
       " '3250539f-8ea9-4c83-ab15-79643edb1f24',\n",
       " '7f79378a-9ddb-4915-af5c-04da16208ad9',\n",
       " '756ce95d-050b-4e5e-9fd7-6ed330a0ac0a',\n",
       " 'c10e0711-d69e-4ad8-bcfe-c064c41dc84d',\n",
       " '6d2f7b73-bc21-4394-9dab-8be237710ade',\n",
       " '0e4e3262-af4a-4488-92ad-7ca41754697b',\n",
       " 'eac4712a-3c18-446d-817e-1050d996942b',\n",
       " '78a55b98-cfd2-45ca-ae40-515ad7180dce',\n",
       " '65c50bb9-a0e7-46a5-82a3-1d32c74d67fb',\n",
       " '6de733d4-e6c2-496b-9d80-bd5c7f686de4',\n",
       " '76788749-943b-44bc-bc21-fb301ed67fa4',\n",
       " '8522b83b-a8d9-4cf3-9220-bc9041238ea8',\n",
       " '5a8e5d41-40b6-40ad-9dd7-5dfe91290394',\n",
       " '6101a569-af60-4dac-8a49-b12f14529d41',\n",
       " '9f293a23-5b36-456f-9250-d204d8d419f4',\n",
       " 'f6ee447f-54b0-4847-a77d-bfe7ec5a83ac',\n",
       " 'e6ebc20c-48ff-4b59-be4d-32ee7454fe26',\n",
       " 'ebcdc45d-a86a-44d1-96e4-3e755bd3c6f4',\n",
       " '2544b484-fcf1-4fbb-8206-ca61a3ac8429',\n",
       " '4c19ea45-78a6-4076-9185-11b0a7e3529e',\n",
       " '0a1055d9-aa4c-47af-985d-894064dc41db',\n",
       " 'cbc67fe8-9be2-4677-840d-a5928b727b32',\n",
       " '6f6ac946-a3b5-4e34-bb68-a7af23c83350',\n",
       " 'd4c417f1-cfa2-44c8-a933-43111dc08538',\n",
       " '69489c86-eeb7-4f90-8018-c80962dc616b',\n",
       " '43617aa4-78ac-479d-8776-59a1680b30ed',\n",
       " '0a599328-e221-4253-8a0e-8aca1e0a9492',\n",
       " 'c8ba009d-c733-4607-b484-c5b005414087',\n",
       " 'e2aeeb6c-bac7-483e-b0a2-55df0769d043',\n",
       " 'f1210cf1-ed80-4fc0-958c-6ef4f3957e6f',\n",
       " '2c77706c-7197-4773-ac93-20272dc915a9',\n",
       " '98f8b259-c3c0-4f41-a168-bb5fbc118fc0',\n",
       " 'fbe3d6b7-595d-4a73-b460-d26c1584f371',\n",
       " '6ba1b1a8-e925-47c2-9504-e02a3c9accb9',\n",
       " 'fb4e3b3e-80dc-41fa-8da2-88e3a732bf39',\n",
       " '13b02c7d-18fe-4670-91e8-13e487b06592',\n",
       " '3026c53e-9580-47a6-a3e4-29f34cd0b9d0',\n",
       " '80469ed6-0a37-43b4-85b9-5628bc8d6d7c',\n",
       " '32798fce-642f-4816-a4e6-7d1584e675b3',\n",
       " '488c7a01-e5fb-4c0f-a466-1fe703b31f71',\n",
       " '5612ca60-ba29-4eb1-8f0c-8c71bd9f5ba3',\n",
       " '2efe8612-8085-4d9a-a293-08e4e0605872',\n",
       " 'e9d8ccb6-c67a-4cfc-b233-e846bc4d61fc',\n",
       " '5ed156d2-e196-4494-a809-a0eceb714df1',\n",
       " '33c89543-0801-45f2-948b-4e4e56103114',\n",
       " '7f3d2cb9-463c-42b2-9bef-9332a1048cce',\n",
       " '569654e5-3714-4bb9-9eee-7765b07d5a94',\n",
       " '85942b89-2d84-439b-a6b3-afe80c434b81',\n",
       " '421fdfdc-b40a-40b4-8c24-f6f949eb4c77',\n",
       " 'b1420b23-ce72-48ed-b380-95d1470d6b75',\n",
       " '8544e076-509a-493f-a671-5ff0655b6c09',\n",
       " '70de468d-d993-4978-aeb2-6bb73038cad8']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding_dim = len(embeddings.embed_query(\"hello world\"))\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    "    normalize_L2=True\n",
    ")\n",
    "\n",
    "vector_store.add_documents(documents=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "39c71595501b4099b86a137eecf48618",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758276629,
    "source_hash": "2ca0bc3c"
   },
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "dca3c25d995f4dcaa99e9e38d24247c9",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 1,
    "execution_start": 1759758276689,
    "source_hash": "aa4529ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieved doc 1 ---\n",
      "w  d n.\n",
      "‚Äì I  B   ich d   Bildv  a   itung w  d n s lch  \n",
      "M d ll   √º  Au ga  n wi  Bildklassi izi  ung,\n",
      "O j kt  k nnung  d   Bildg n  i  ung  ing s tzt.\n",
      "‚Äì In d   Audi v  a   itung  ind n sich \n",
      "Anw ndung n in Sp ach  k nnung, \n",
      "Musikk  p siti n  d   S undanalys . ...\n",
      "\n",
      "--- Retrieved doc 2 ---\n",
      "Prof. Dr. Manuel Renold\n",
      "Was ist in LLMs drin?\n",
      "GenAI & LLMs\n",
      "28\n",
      "Bild: https://lifearchitect.ai/whats-in-my-ai/ ...\n",
      "\n",
      "--- Retrieved doc 3 ---\n",
      "Prof. Dr. Manuel Renold\n",
      "‚Äì T  p  atu : R guli  t di  Zu √§lligk it d   Antw  t n  in s Sp ach  d lls.\n",
      "‚Äì Ein luss: H√∂h    W  t    h√∂h n di  Vi l alt, ni d ig    W  t  s  g n  √º  V  h  s h a k it.\n",
      "‚Äì Anpassung: Einst ll a , u  K  ativit√§t  d   P √§zisi n zu st ig  n.\n",
      "P   pt Engin   ing: T  p  atu ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuel\\AppData\\Local\\Temp\\ipykernel_26236\\2010197779.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(\"Pr√§dikatenlogik\")\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"Pr√§dikatenlogik\")\n",
    "for i, d in enumerate(docs, 1):\n",
    "    print(f\"--- Retrieved doc {i} ---\")\n",
    "    print(d.page_content[:400], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "7628494db79b4133966fb98d4c707ab8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "chain = (\n",
    "{\n",
    "    \"context\": retriever,\n",
    "    \"question\": RunnablePassthrough(),\n",
    "}\n",
    "    | LERNASSISTENT_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "51912f3cb08b43e4b9d485e1821e52ce",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 25790,
    "execution_start": 1759758276799,
    "source_hash": "51d1e9bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dazu habe ich im bereitgestellten Material nichts.  \n",
      "Bitte laden Sie die Folie oder den Abschnitt hoch, in dem Pr√§dikatenlogik behandelt wird (z.‚ÄØB. Titel‚ÄØ/‚ÄØSeite‚ÄØ/‚ÄØKapitel).\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# USER_PROMPT=\"Generiere mir einen Post f√ºr die PubTour am 16. Oktober\"\n",
    "\n",
    "# result = chain.invoke(\"Generiere mir einen Post f√ºr die PubTour am 16. Oktober\")\n",
    "# print(result)\n",
    "\n",
    "result = chain.invoke(\"Was ist Pr√§dikatenlogik?\")\n",
    "print(result)\n",
    "\n",
    "#result = chain.invoke(user_prompt)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer(question: str) -> str:\n",
    "    # Kein LangSmith, einfach direkt die Chain ausf√ºhren\n",
    "    try:\n",
    "        response = chain.invoke(question)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Fehler bei der Verarbeitung: {e}\"\n",
    "\n",
    "# --- Gradio UI ---\n",
    "demo = gr.Interface(\n",
    "    fn=answer,\n",
    "    inputs=gr.Textbox(label=\"Question\", placeholder=\"Type your question here...\"),\n",
    "    outputs=gr.Textbox(label=\"Answer\", lines=10),\n",
    "    title=\"Lernassistent BAI\",\n",
    "    description=\"Stelle Fragen zum Lernstoff der BAI und erhalte pr√§zise, pr√ºfungsrelevante Antworten.\",\n",
    ")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=56a0a349-7f2e-43e5-8d52-5ded467f6e9c' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "b03039a6aad547a39dea08ca00c7302d",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
